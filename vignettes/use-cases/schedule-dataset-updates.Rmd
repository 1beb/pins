---
title: "Schedule Dataset Updates"
output:
  html_document:
    df_print: paged
---

After a datasets are shared (as showcased in the [Reuse Tidy Datasets](reuse-tidy-datasets.htm) use case), it is often useful to also consider automating this process. This is specially interesting for datasets that tend to get out-of-date constantly. This would be the case if we were interesting in maintaining a pin to track daily news through the following repos:

````markdown
---
title: "RStudio Connect -- World News"
---

`r ''````{r, setup, include = FALSE}
library(pins)
board_register_rsconnect(key = Sys.getenv("RSCONNECT_API"),
                         server = "https://rstudio-connect-server")
```

Create the `world_news` data frame,

`r ''````{r  fig.align='center', warning=FALSE}
library(xml2)

world_news <- data.frame(title = xml_text(xml_find_all(
  read_xml("http://feeds.bbci.co.uk/news/rss.xml"), "///item/title/node()")))
```

Which you can then share as a pin,

`r ''````{r}
pin(world_news, "worldnews", board = "rsconnect")
```
````

While you can run manually this report each time you need the `worldnews` pin update, using automated techniques makes so much sense.

The `pins` package does not provide support to schedule execution of R code; however, many tools and services can be used in combination with `pins` to update datasets with ease. For instance, when using GitHub, Travis can be used in combination with a `GITHUB_PAT` environment variable to knit this daily news report and update pins in GitHub. Similarily, using RStudio Connect, we can easily publish this report and configure RStudio Connect to run this daily -- the pin will then be kept up to date every day automatically!

You can take a look at this up-to-date daily news dataset at [beta.rstudioconnect.com/connect/#/apps/6446/access](https://beta.rstudioconnect.com/connect/#/apps/6446/access) or preview this bellow:

[![](images/schedule-updates-rsconnect.png)](https://beta.rstudioconnect.com/connect/#/apps/6446/access)
