---
title: "pins: Track, Discover and Share Datasets"
output:
  github_document:
    fig_width: 9
    fig_height: 5
---

```{r setup, echo=FALSE, message=FALSE}
pins::unpin("iris-small-width")
pins::unpin("hacker-news-scores")
pins::unpin("bigquery")
pins::unpin("hacker-news-full")

bq_project <- Sys.getenv("BQ_PROJECT")
bq_dataset <- Sys.getenv("BQ_DATASET")

knitr::opts_chunk$set(eval = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.path = "tools/readme/", dev = "png")
```

# pins 

[![Build Status](https://travis-ci.org/javierluraschi/pins.svg?branch=master)](https://travis-ci.org/javierluraschi/pins) [![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/pins)](https://cran.r-project.org/package=pins)

- **Track** local and remote datasets using `pin()` and `get_pin()`.
- **Discover** new datasets from R packages, online and your organization using `find_pin()`.
- **Share** datasets with your team, or the world, using customizable boards through `use_board()`.
- **Extend** storage locations with custom boards, you decide where your data lives.

## Installation

You can install `pins` using the `remotes` package:

```{r install, eval = FALSE}
install.packages("remotes")
remotes::install_github("rstudio/pins")
```

## Tracking Datasets

It's easy to track local datasets using `pin()` and `get_pin()`. In addition, you can retrive remote datasets using `DBI` or pin remote datasets without retrieving them using `dplyr`.

### Local Datasets

You can track your datasets privately by pinning with `pin()`.

```{r local-pin}
library(dplyr, warn.conflicts = FALSE)
library(pins)

iris %>%
  filter(Sepal.Width < 3, Petal.Width < 1) %>%
  pin("iris-small-width", "A subset of 'iris' with only small widths.")
```

You can then retrieve them back with `get_pin()`.

```{r local-get-pin}
get_pin("iris-small-width")
```

A pin is a tool to help you track your datasets to easily fetch results from past data analysis sessions.

For instance, once a dataset is tidy, you are likely to reuse it several times. You might also have a past analysis in GitHub, but you might not want to clone, install dependencies and rerun your code just to access your dataset. Another use case is to cross-join between datasets to analyse across multiple projects or help you remember which datasets you've used in the past.

### Remote Datasets

Some datasets are stored in datasets which you usually access with `DBI` or `dplyr`. For instance, you might want to access a public dataset stored in `bigrquery`:

```{r remote-con}
con <- DBI::dbConnect(bigrquery::bigquery(), project = bq_project, dataset = bq_dataset)
```

Which we can analyze with `DBI` and then pin the results locally:

```{r remote-dbi, results = 'hide'}
DBI::dbGetQuery(con, "
  SELECT score, count(*) as n
  FROM (SELECT 10 * floor(score/10) as score FROM `bigquery-public-data.hacker_news.full`)
  GROUP BY score") %>%
  pin("hacker-news-scores", "Hacker News scores grouped by tens.")
```

However, you can only use `DBI` when you can fetch all the data back into R, this is not feasible in many cases. Instead, when using `dplyr`, you can pin large datasets and transform them without having to fetch any data at all.

Lets pin the entire dataset using `dplyr`:

```{r remote-dplyr-pin}
tbl(con, "bigquery-public-data.hacker_news.full") %>%
  pin("hacker-news-full")
```

This works well if you provide the connection, after your R session gets restarted, you would have to provide a connection yourself before retrieving the pin:

```{r remote-dplyr-get, results = 'hide'}
con <- DBI::dbConnect(bigrquery::bigquery(), project = bq_project, dataset = bq_dataset)
get_pin("hacker-news-full")
```

This is acceptable but not ideal -- it's hard to remember what connection to use for each dataset. So instead, pin a connection:

```{r remote-dplyr-con}
con <- pin(~DBI::dbConnect(bigrquery::bigquery(), project = bq_project, dataset = bq_dataset), "bigquery")
```

Then pin your dataset as you would usually would,

```{r remote-dplyr-con-pin, results = 'hide'}
tbl(con, "bigquery-public-data.hacker_news.full") %>%
  pin("hacker-news-full", "The Hacker News dataset in Google BigQuery.")
```

From now on, after restarting your R session and retrieving the pin, the pin will initialize the connection before retrieving a `dplyr` reference to it with `pin("hacker-news-full")`.

Which in turn, allows you to further process the datset using `dplyr` and pin additional remote datasets.

```{r remote-dplyr-query-pin, results = 'hide'}
get_pin("hacker-news-full") %>%
  transmute(score = 10 * floor(score/10)) %>%
  group_by(score) %>%
  summarize(n = n()) %>%
  filter(score < 2000) %>%
  pin("hacker-news-scores")
```

You can then use this `dplyr` pin to process data further; for instance, by visualizing it with ease:

```{r remote-dplyr-plot}
library(ggplot2)

get_pin("hacker-news-scores") %>%
  ggplot() +
    geom_bar(aes(x = score, y = n), stat="identity") +
    scale_y_log10() + theme_light()
```

You can also cache this dataset locally by running `collect()` on the pin and then re-pinning it with `pin()`.

## Discovering Datasets

The `pins` package can help you discover interesting datasets, currently it searches datasets inside CRAN packages but we are planning to extend this further.

You can search datasets that contain "seattle" in their description or name as follows:

```{r discover-pin}
find_pin("seattle")
```

You can the retrieve a specific dataset with `get_pin()`:

```{r discover-get-pin}
get_pin("hpiR_seattle_sales")
```

## Sharing Datasets

`pins` supports shared storage locations using boards. A board is a remote location for you to share pins with your team privately, or with the world, publicly. Use `use_board()` to choose a board, currently `database` and `arrow` boards are supported; however, `pins` provide an extensible API you can use to store pins anywhere.

### Arrow

In order to share datasets with other programming languages, an `arrow` board can be used. This board uses Apache Arrow to share datasets across R and Python and can be easily activated as follows:

```{r}
use_board("arrow")
```

The you can pin and retrieve pins as usual.

```{r}
mtcars %>% pin("cars")
get_pin("cars")
```

While the functionality is similar, pins are stored using the Apache Arrow format which can be easily read from Python and many other languages.

### Databases

We can reuse our `bigrquery` connection to define a database-backed shared board,

```{r db-board}
use_board("database", con)
```

Which we can also use to pin a dataset,

```{r db-pin, warning = FALSE}
pin(iris, "iris", "The entire 'iris' dataset.")
```

find pins,

```{r db-find-pin}
find_pin()
```

and retrieve shared datasets.

```{r db-get-pin}
get_pin("iris")
```

### Connections

Connections can also be pinned to shared boards; however, you should pin them using a proper connection object, not an R formula:

```{r shared-connection-dbi, eval=FALSE}
con <- pin_connection("bigquery", driver = "bigrquery::bigquery", project = bq_project, dataset = bq_dataset)
```

Other packages that don't use `DBI` connections, like `sparklyr`, can use an explicit `initializer` function:

```{r shared-connection-sparklyr, eval=FALSE}
sc <- pin_connection(
  "spark-local",
  "sparklyr::spark_connect",
  master = "local",
  config = list("sparklyr.shell.driver-memory" = "4g")
)
```

**Note:** Remove username, password and other sensitive information from your pinned connections. By default, `username` and `password` fields will be replaced with "@prompt", which will prompt the user when connecting.

## RStudio

This package provides an [RStudio Addin](https://rstudio.github.io/rstudio-extensions/rstudio_addins.html) to search for datasets and an [RStudio Connection](https://rstudio.github.io/rstudio-extensions/rstudio-connections.html) extension to track local or remote datasets.

![](tools/readme/rstudio-pins-addmin.png)

The addin provides a list of datasets and visual clues that describe how large and wide eachd dataset is.
